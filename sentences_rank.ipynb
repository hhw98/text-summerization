{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "import math\n",
    "#from util import split_sentence\n",
    "from termcolor import colored, cprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_sentence(text):\n",
    "    #remove strange character\n",
    "    text = text.replace(\"\\r\\n\",\"\")\n",
    "    #split sentences\n",
    "    sentences = re.split('([。?!！？.])', text)\n",
    "    new_sentences = []\n",
    "    for i in range(len(sentences)//2):\n",
    "        sent = sentences[2*i] + sentences[2*i+1]\n",
    "        new_sentences.append(sent)\n",
    "    return new_sentences\n",
    "def get_stop_words(stopwords_file):\n",
    "    stop_words = []\n",
    "    for line in open(stopwords_file, 'r', encoding='utf-8'):\n",
    "        stop_words.append(line.replace('\\n', ''))\n",
    "    return stop_words\n",
    "\n",
    "#Chinese\n",
    "def get_token(sent):\n",
    "    #remove punctuation for Chinese\n",
    "    sent = re.findall(r'[\\d|\\w]+', sent)\n",
    "    stopwords = get_stop_words(\"stopwords.txt\")\n",
    "    #Chinese\n",
    "    words = list(jieba.cut(\"\".join(sent)))\n",
    "    #remove stopwords\n",
    "    words = list(set(words) - set(stopwords))\n",
    "    return words\n",
    "\n",
    "#English\n",
    "def get_token(sent):\n",
    "\n",
    "    stopwords = get_stop_words(\"stopwords.txt\")\n",
    "\n",
    "    words = list(sent.split())\n",
    "    #remove stopwords\n",
    "    words = list(set(words) - set(stopwords))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../sqlResult_1558435.csv\", encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>feature</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>89617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...</td>\n",
       "      <td>小米MIUI 9首批机型曝光：共计15款</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623597.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>89616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...</td>\n",
       "      <td>骁龙835在Windows 10上的性能表现有望改善</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623599.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>89615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...</td>\n",
       "      <td>一加手机5细节曝光：3300mAh、充半小时用1天</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623601.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id author                  source  \\\n",
       "0  89617    NaN  快科技@http://www.kkj.cn/   \n",
       "1  89616    NaN  快科技@http://www.kkj.cn/   \n",
       "2  89615    NaN  快科技@http://www.kkj.cn/   \n",
       "\n",
       "                                             content  \\\n",
       "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...   \n",
       "1  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...   \n",
       "2  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...   \n",
       "\n",
       "                                             feature  \\\n",
       "0  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...   \n",
       "1  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...   \n",
       "2  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...   \n",
       "\n",
       "                        title                                             url  \n",
       "0        小米MIUI 9首批机型曝光：共计15款  http://www.cnbeta.com/articles/tech/623597.htm  \n",
       "1  骁龙835在Windows 10上的性能表现有望改善  http://www.cnbeta.com/articles/tech/623599.htm  \n",
       "2   一加手机5细节曝光：3300mAh、充半小时用1天  http://www.cnbeta.com/articles/tech/623601.htm  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarization_by_textrank(text = None, title = None, summary_ratio = None):\n",
    "    \"\"\"\n",
    "    text : text body of news\n",
    "    title: title of news\n",
    "    summary ratio : ratio of sentence number between text body and summary\n",
    "    \"\"\"\n",
    "    if text == None:\n",
    "        print(\"please input text !\")\n",
    "        return None\n",
    "    #get sentence ranking\n",
    "    ranking_sentences_id, sentences = sentences_ranking(text, title)\n",
    "    \n",
    "    print(\"The number of text : \", len(ranking_sentences_id))\n",
    "    \n",
    "    sentence_candidates = ranking_sentences_id[:len(sentences)//summary_ratio]\n",
    "    \n",
    "    print(\"The number of summarization: \", len(sentence_candidates))\n",
    "    #print(sentence_candidates)\n",
    "    #print(sentences)\n",
    "    return \" \".join([sentences[s[0]] for s in sorted(sentence_candidates)])\n",
    "    #text = colored('Hello, World!', 'red', attrs=['reverse', 'blink'])+'hello'\n",
    "    #index_list = [s[0] for s in sorted(sentence_candidates)]\n",
    "    #text = \"\"\n",
    "    #for ii, s in enumerate(sentences):\n",
    "    #    if ii in index_list:\n",
    "    #        text += colored(sentences[ii], 'red', attrs=['reverse', 'blink'])\n",
    "    #    else:\n",
    "    #        text += sentences[ii]\n",
    "    #return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_ranking(text, title):\n",
    "    #get sentences graph\n",
    "    sentences, sentences_graph, title_flag = get_connect_graph_by_weight_text_rank(text, title)\n",
    "    #get sentence rank\n",
    "    ranking_sentences = nx.pagerank(sentences_graph)\n",
    "\n",
    "    #sort except for title\n",
    "    if title_flag:\n",
    "        ranking_sentences.pop(0)\n",
    "\n",
    "    sorted_ranking_sentences = sorted(ranking_sentences.items(), key = lambda x:x[1], reverse = True)\n",
    "    return sorted_ranking_sentences, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connect_graph_by_weight_text_rank(text, title):\n",
    "    \"\"\"\n",
    "    text : text body for one news\n",
    "    title: title for one news\n",
    "    \"\"\"\n",
    "    #text preprocess\n",
    "    sentences = split_sentence(text)\n",
    "    tokens = [get_token(s) for s in sentences]\n",
    "    #title preprocess\n",
    "    title_flag = False\n",
    "    #if title:\n",
    "    #    title_token = get_token(title)\n",
    "    #    if title_token:\n",
    "    #        title_flag = True\n",
    "    #        tokens.insert(0, title_token)\n",
    "    #        sentences.insert(0, title)\n",
    "    #add edges\n",
    "    sentences_graph = nx.Graph()\n",
    "    for ii, sentence in enumerate(tokens):\n",
    "        for i in range(ii+1, len(tokens)):\n",
    "            num_same_words = len(set(tokens[ii]).intersection(set(tokens[i])))\n",
    "            #double weight for first sentence\n",
    "            if ii == 0:\n",
    "                similarity = 2 * num_same_words / (math.log(len(tokens[ii])) + math.log(len(set(tokens[i])))) \n",
    "            else:\n",
    "                similarity = num_same_words / (math.log(len(tokens[ii])) + math.log(len(set(tokens[i]))))\n",
    "            \n",
    "            sentences_graph.add_edges_from([(ii, i)],weight = similarity)\n",
    "    return sentences, sentences_graph, title_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of text :  9\n",
      "The number of summarization:  3\n",
      "[(5, 0.13963011201012046), (8, 0.1343225054735141), (0, 0.13279828696284351)]\n",
      "['IT HAS BECOME A RECENT COMMONPLACE to recognize that regions, like nations, are imagined constructs, that they possess historical specificity and are imagined differently by different people at various times.', '1 It is less well acknowledged, however, that there are also flexible imaginaries that perhaps are related to and extend already existing structures, or that turn against these structures and contest their claims.', '2 These flexible imaginaries require looking at specific moments and episodes that have either been repressed by state-centered narratives of history or displaced by nostalgic yearnings for the local in an environment of dominating global and total structures.', ' This essay focuses on a moment in early twentieth-century China during which Asia was first created as a regional construct by a small but influential group of Chinese intellectuals, who, in collaboration with other peoples residing in Tokyo, attempted to rethink modes of political action and organization.', ' The Asia that resulted from these activities and rethinkings was shaped by, albeit not limited to, two simultaneous structures: imperialism and ongoing attempts to subject the non-West to a Western-dominated world system; and state-dominated concepts of national and regional formation.', ' These two structural trends helped produce a concept of Asia that is well known to historians: an anti-imperialist and yet state-centered regional formation that has episodically resulted in various state-led pan-Asianisms over the course of the ensuing century.', \" Sun Zhongshan's (Sun Yat-sen) state-based, anti-imperialist vision of Asia is the most familiar of these versions.\", ' However, a different discourse of Asia was also produced at this time, one that was rooted in non-state-centered practices and in non-national-chauvinist cultur- alism.', ' This alternative Asia discourse and practice represented an attempt to create a radically politicized cultural regional concept, whose historical resonance seems, however, to have been almost permanently displaced by the more strident versions of the region that uphold the primacy of the nation-state and capitalist developmentalism.']\n",
      "IT HAS BECOME A RECENT COMMONPLACE to recognize that regions, like nations, are imagined constructs, that they possess historical specificity and are imagined differently by different people at various times.  These two structural trends helped produce a concept of Asia that is well known to historians: an anti-imperialist and yet state-centered regional formation that has episodically resulted in various state-led pan-Asianisms over the course of the ensuing century.  This alternative Asia discourse and practice represented an attempt to create a radically politicized cultural regional concept, whose historical resonance seems, however, to have been almost permanently displaced by the more strident versions of the region that uphold the primacy of the nation-state and capitalist developmentalism.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    text = \"网易娱乐7月21日报道林肯公园主唱查斯特·贝宁顿 Chester Bennington于今天早上,在洛杉矶帕洛斯弗迪斯的一个私人庄园自缢身亡,年仅41岁。此消息已得到洛杉矶警方证实。洛杉矶警方透露, Chester的家人正在外地度假, Chester独自在家,上吊地点是家里的二楼。一说是一名音乐公司工作人员来家里找他时发现了尸体,也有人称是佣人最早发现其死亡。林肯公园另一位主唱麦克信田确认了 Chester Bennington自杀属实,并对此感到震惊和心痛,称稍后官方会发布声明。Chester昨天还在推特上转发了一条关于曼哈顿垃圾山的新闻。粉丝们纷纷在该推文下留言,不相信 Chester已经走了。外媒猜测,Chester选择在7月20日自杀的原因跟他极其要好的朋友Soundgarden(声音花园)乐队以及AudioslaveChris乐队主唱 Cornell有关,因为7月20日是 Chris CornellChris的诞辰。而 Cornell于今年5月17日上吊自杀,享年52岁。 Chris去世后, Chester还为他写下悼文。对于 Chester的自杀,亲友表示震惊但不意外,因为 Chester曾经透露过想自杀的念头,他曾表示自己童年时被虐待,导致他医生无法走出阴影,也导致他长期酗酒和嗑药来疗伤。目前,洛杉矶警方仍在调查Chester的死因。据悉, Chester与毒品和酒精斗争多年,年幼时期曾被成年男子性侵,导致常有轻生念头。 Chester生前有过2段婚姻,育有6个孩子。林肯公园在今年五月发行了新专辑《多一丝曙光OneMoreLight》,成为他们第五张登顶ilboard排行榜的专辑。而昨晚刚刚发布新单《 Talking To Myself》MV\"\n",
    "    #text = data[\"content\"][6]\n",
    "    #title = data[\"title\"][4]#\n",
    "    text = \"I took EECS 545 machine learning class last semester. I implement different kinds of supervised machine learning algorithm step by step in python. For example, kNN classifier, Regularized  Linear  Regression, Weighted Linear Regression, logistic regression, ridge regression, Support Vector Regression, Bayesian, Gradient and Coordinate Decent and Neural Nets. And some supervised machine learning algorithm, like LDA, QDA, K-means, pca. Thus, I am not only familiar how to use machine learning model from some packages, like sklearn, but also know about how to implement in python and mathematic  deduction behind different model. In addition, I have some deep learning experiences with machine learning framework, like PyTorch and Tensorflow. \"\n",
    "    title = None\n",
    "\n",
    "    \n",
    "    text = \"IT HAS BECOME A RECENT COMMONPLACE to recognize that regions, like nations, are imagined constructs, that they possess historical specificity and are imagined differently by different people at various times.1 It is less well acknowledged, however, that there are also flexible imaginaries that perhaps are related to and extend already existing structures, or that turn against these structures and contest their claims.2 These flexible imaginaries require looking at specific moments and episodes that have either been repressed by state-centered narratives of history or displaced by nostalgic yearnings for the local in an environment of dominating global and total structures. This essay focuses on a moment in early twentieth-century China during which Asia was first created as a regional construct by a small but influential group of Chinese intellectuals, who, in collaboration with other peoples residing in Tokyo, attempted to rethink modes of political action and organization. The Asia that resulted from these activities and rethinkings was shaped by, albeit not limited to, two simultaneous structures: imperialism and ongoing attempts to subject the non-West to a Western-dominated world system; and state-dominated concepts of national and regional formation. These two structural trends helped produce a concept of Asia that is well known to historians: an anti-imperialist and yet state-centered regional formation that has episodically resulted in various state-led pan-Asianisms over the course of the ensuing century. Sun Zhongshan's (Sun Yat-sen) state-based, anti-imperialist vision of Asia is the most familiar of these versions. However, a different discourse of Asia was also produced at this time, one that was rooted in non-state-centered practices and in non-national-chauvinist cultur- alism. This alternative Asia discourse and practice represented an attempt to create a radically politicized cultural regional concept, whose historical resonance seems, however, to have been almost permanently displaced by the more strident versions of the region that uphold the primacy of the nation-state and capitalist developmentalism.\"\n",
    "    summary_ratio = 3\n",
    "    summarization = get_summarization_by_textrank(text, title, summary_ratio)\n",
    "    print(summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mHello\u001b[0mworld\n"
     ]
    }
   ],
   "source": [
    "def blueprint(x):\n",
    "    print('\\033[34m' + str(x) + '\\033[0m'+\"world\")\n",
    "blueprint(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and in dim text\u001b[42mand with a green background\n",
      "\u001b[42mand with a green background\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "print('and in dim text'+Back.GREEN + 'and with a green background')\n",
    "print(Back.GREEN + 'and with a green background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'light_red'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f0d13f20f30c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtermcolor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolored\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Hello, World!'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'light_red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reverse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'blink'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcolored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Hello, World!'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reverse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'blink'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Hello, World!'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'on_red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\stanfordnlp\\lib\\site-packages\\termcolor.py\u001b[0m in \u001b[0;36mcolored\u001b[1;34m(text, color, on_color, attrs)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfmt_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\033[%dm%s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmt_str\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mCOLORS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mon_color\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'light_red'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from termcolor import colored, cprint\n",
    "\n",
    "text = colored('Hello, World!', 'light_red', attrs=['reverse', 'blink'])+colored('Hello, World!', 'red', attrs=['reverse', 'blink'])\n",
    "print(text)\n",
    "cprint('Hello, World!', 'green', 'on_red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from termcolor import colored, cprint\n",
    "\n",
    "text = colored('Hello, World!', 'red', attrs=['reverse', 'blink'])+'hello'\n",
    "print(text)\n",
    "cprint('Hello, World!', 'green', 'on_red')\n",
    "\n",
    "print_red_on_cyan = lambda x: cprint(x, 'red', 'on_cyan')\n",
    "print_red_on_cyan('Hello, World!')\n",
    "print_red_on_cyan('Hello, Universe!')\n",
    "\n",
    "for i in range(10):\n",
    "    cprint(i, 'magenta', end=' ')\n",
    "\n",
    "cprint(\"Attention!\", 'red', attrs=['bold'], file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcolors.name_to_rgb('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
